import streamlit as st
import cv2
import numpy as np
from PIL import Image
import easyocr
from ultralytics import YOLO
import os

# --- Set page configuration ---
st.set_page_config(
    page_title="corsarious",
    layout="wide",
    page_icon="ğŸ§‘â€âš•ï¸"
)

# --- Main Application ---
# Initialize EasyOCR reader
reader = easyocr.Reader(['en'], verbose=True)

# Load the YOLO model
model_path = "yolov5s.pt" Â # Path to your downloaded YOLOv5 model
model = YOLO(model_path)

# Streamlit app title
st.title("P&ID Instrumentation and Symbol Detection")

# File uploader for image input
uploaded_file = st.file_uploader("Upload an Image (PNG, JPG, JPEG)", type=["jpg", "jpeg", "png", "PNG"])

if uploaded_file is not None:
Â  Â  # Read the uploaded image
Â  Â  file_bytes = np.asarray(bytearray(uploaded_file.read()), dtype=np.uint8)
Â  Â  img = cv2.imdecode(file_bytes, cv2.IMREAD_COLOR)
Â  Â  original_img = img.copy()

Â  Â  # Display the uploaded image
Â  Â  st.subheader("Uploaded Image:")
Â  Â  st.image(img, channels="BGR")

Â  Â  # --- YOLO Symbol Detection ---
Â  Â  st.subheader("Symbol Detection with YOLOv5 (yolov5s.pt)")

Â  Â  # Perform inference with the YOLO model
Â  Â  results = model(img)

Â  Â  # Display the results
Â  Â  st.subheader("Detection Results:")

Â  Â  # Access bounding boxes, labels, and confidence scores
Â  Â  for *xyxy, conf, cls in results[0].boxes.data: Â # Get bounding boxes and other info
Â  Â  Â  Â  label = model.names[int(cls)]
Â  Â  Â  Â  x_min, y_min, x_max, y_max = map(int, xyxy) Â # Get bounding box coordinates
Â  Â  Â  Â  st.write(f"Detected: {label} with confidence {conf:.2f}")
Â  Â  Â  Â  cv2.rectangle(img, (x_min, y_min), (x_max, y_max), (0, 255, 0), 2)

Â  Â  # Display annotated image with YOLO results
Â  Â  st.image(img, caption="YOLO Annotated Image", use_column_width=True)

Â  Â  # --- EasyOCR Text Detection and Shape Detection ---
Â  Â  st.subheader("Text Extraction and Shape Detection")

Â  Â  # Preprocessing for contours
Â  Â  gray = cv2.cvtColor(original_img, cv2.COLOR_BGR2GRAY)
Â  Â  blurred = cv2.GaussianBlur(gray, (5, 5), 0)
Â  Â  edges = cv2.Canny(blurred, 50, 150)
Â  Â  kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))
Â  Â  dilated = cv2.dilate(edges, kernel, iterations=2)
Â  Â  contours, _ = cv2.findContours(dilated, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

Â  Â  # Detect and annotate instrument shapes
Â  Â  instrument_shapes = []
Â  Â  for contour in contours:
Â  Â  Â  Â  x, y, w, h = cv2.boundingRect(contour)
Â  Â  Â  Â  if 50 < w < 500 and 50 < h < 500: Â # Adjust thresholds as needed
Â  Â  Â  Â  Â  Â  instrument_shapes.append((x, y, w, h))
Â  Â  Â  Â  Â  Â  cv2.rectangle(original_img, (x, y), (x + w, y + h), (255, 0, 0), 2)

Â  Â  # Detect circles using Hough Circle Transform
Â  Â  gray_blur = cv2.GaussianBlur(gray, (9, 9), 2)
Â  Â  circles = cv2.HoughCircles(
Â  Â  Â  Â  gray_blur,
Â  Â  Â  Â  cv2.HOUGH_GRADIENT,
Â  Â  Â  Â  dp=1,
Â  Â  Â  Â  minDist=50,
Â  Â  Â  Â  param1=50,
Â  Â  Â  Â  param2=30,
Â  Â  Â  Â  minRadius=10,
Â  Â  Â  Â  maxRadius=50
Â  Â  )

Â  Â  # Draw circles on the original image
Â  Â  if circles is not None:
Â  Â  Â  Â  circles = np.uint16(np.around(circles))
Â  Â  Â  Â  for circle in circles[0, :]:
Â  Â  Â  Â  Â  Â  center = (circle[0], circle[1]) Â # x, y center
Â  Â  Â  Â  Â  Â  radius = circle[2] Â # radius
Â  Â  Â  Â  Â  Â  cv2.circle(original_img, center, radius, (0, 255, 0), 2)

Â  Â  # Display detected shapes and text
Â  Â  st.subheader("Processed Image with Detected Shapes and Circles")
Â  Â  st.image(original_img, channels="BGR")

Â  Â  # Extract text from detected shapes
Â  Â  st.subheader("Extracted Text from Detected Shapes and Circles")
Â  Â  cols = st.columns(3)

Â  Â  for i, (x, y, w, h) in enumerate(instrument_shapes):
Â  Â  Â  Â  cropped_shape = img[y:y + h, x:x + w]
Â  Â  Â  Â  text = reader.readtext(cropped_shape, detail=0)
Â  Â  Â  Â  extracted_text = " ".join(text) if text else "No text detected"
Â  Â  Â  Â  with cols[i % 3]:
Â  Â  Â  Â  Â  Â  st.image(cropped_shape, caption=f"Shape {i + 1}")
Â  Â  Â  Â  Â  Â  st.write(f"Text: {extracted_text}")

Â  Â  if circles is not None:
Â  Â  Â  Â  for i, circle in enumerate(circles[0, :]):
Â  Â  Â  Â  Â  Â  x, y, r = circle
Â  Â  Â  Â  Â  Â  cropped_circle = original_img[y-r:y+r, x-r:x+r]
Â  Â  Â  Â  Â  Â  if cropped_circle.size > 0:
Â  Â  Â  Â  Â  Â  Â  Â  text = reader.readtext(cropped_circle, detail=0)
Â  Â  Â  Â  Â  Â  Â  Â  extracted_text = " ".join(text) if text else "No text detected"
Â  Â  Â  Â  Â  Â  Â  Â  with cols[(i + len(instrument_shapes)) % 3]:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.image(cropped_circle, caption=f"Circle {i + 1}")
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.write(f"Text: {extracted_text}")
